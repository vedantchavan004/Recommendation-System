{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install PyTorch and torchvision\n",
        "!pip install torch==2.0.1 torchvision==0.15.2\n",
        "\n",
        "# Install PyTorch Geometric dependencies for CUDA 11.7\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.0.1+cu117.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.0.1+cu117.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-2.0.1+cu117.html\n",
        "!pip install torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.1+cu117.html\n",
        "!pip install torch-geometric\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A38P_qzgZ33b",
        "outputId": "6b8de83b-78b3-40ef-ea71-d0e722ab99ec"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.0.1\n",
            "  Downloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Collecting torchvision==0.15.2\n",
            "  Downloading torchvision-0.15.2-cp311-cp311-manylinux1_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.1)\n",
            "  Downloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2) (11.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1) (3.31.6)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (2025.1.31)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n",
            "Downloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.15.2-cp311-cp311-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchvision\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 torchvision-0.15.2 triton-2.0.0\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.1+cu117.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu117/torch_scatter-2.1.2%2Bpt20cu117-cp311-cp311-linux_x86_64.whl (10.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt20cu117\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.1+cu117.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu117/torch_sparse-0.6.18%2Bpt20cu117-cp311-cp311-linux_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.14.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (1.26.4)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt20cu117\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.1+cu117.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu117/torch_cluster-1.6.3%2Bpt20cu117-cp311-cp311-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-cluster) (1.14.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-cluster) (1.26.4)\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3+pt20cu117\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.1+cu117.html\n",
            "Collecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu117/torch_spline_conv-1.2.2%2Bpt20cu117-cp311-cp311-linux_x86_64.whl (887 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.1/887.1 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.2+pt20cu117\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.13)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.1.31)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the MovieLens 100K dataset\n",
        "!wget http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
        "\n",
        "# Unzip the dataset quietly\n",
        "!unzip -q ml-100k.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnT1yr2aZ6O9",
        "outputId": "aa44f35b-1c85-49f6-ecc3-2661facd349c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-16 19:24:57--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4924029 (4.7M) [application/zip]\n",
            "Saving to: ‘ml-100k.zip’\n",
            "\n",
            "ml-100k.zip         100%[===================>]   4.70M  12.1MB/s    in 0.4s    \n",
            "\n",
            "2025-03-16 19:24:57 (12.1 MB/s) - ‘ml-100k.zip’ saved [4924029/4924029]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "# Load ratings (u.data file: user, item, rating, timestamp)\n",
        "ratings = pd.read_csv('ml-100k/u.data', sep='\\t', header=None,\n",
        "                      names=['user', 'item', 'rating', 'timestamp'])\n",
        "\n",
        "# For recommendations, treat ratings >= 4 as positive feedback\n",
        "ratings = ratings[ratings['rating'] >= 4]\n",
        "\n",
        "# Adjust IDs to zero-indexed\n",
        "ratings['user'] = ratings['user'] - 1\n",
        "ratings['item'] = ratings['item'] - 1\n",
        "\n",
        "# Use the maximum value + 1 to get the total number of users and items\n",
        "num_users = int(ratings['user'].max()) + 1\n",
        "num_items = int(ratings['item'].max()) + 1\n",
        "\n",
        "print(f'Number of users: {num_users}, Number of items: {num_items}')\n",
        "ratings.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "naGf1ISKZ9QR",
        "outputId": "290e8459-be48-4e93-8914-392c5569dd4f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of users: 943, Number of items: 1674\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    user  item  rating  timestamp\n",
              "5    297   473       4  884182806\n",
              "7    252   464       5  891628467\n",
              "11   285  1013       5  879781125\n",
              "12   199   221       5  876042340\n",
              "16   121   386       5  879270459"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5f86d06b-a90e-4957-993e-3c999a0abb08\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>item</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>297</td>\n",
              "      <td>473</td>\n",
              "      <td>4</td>\n",
              "      <td>884182806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>252</td>\n",
              "      <td>464</td>\n",
              "      <td>5</td>\n",
              "      <td>891628467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>285</td>\n",
              "      <td>1013</td>\n",
              "      <td>5</td>\n",
              "      <td>879781125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>199</td>\n",
              "      <td>221</td>\n",
              "      <td>5</td>\n",
              "      <td>876042340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>121</td>\n",
              "      <td>386</td>\n",
              "      <td>5</td>\n",
              "      <td>879270459</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f86d06b-a90e-4957-993e-3c999a0abb08')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5f86d06b-a90e-4957-993e-3c999a0abb08 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5f86d06b-a90e-4957-993e-3c999a0abb08');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-48646fcf-60c6-4855-8d91-44e785be7101\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-48646fcf-60c6-4855-8d91-44e785be7101')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-48646fcf-60c6-4855-8d91-44e785be7101 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ratings",
              "summary": "{\n  \"name\": \"ratings\",\n  \"rows\": 55375,\n  \"fields\": [\n    {\n      \"column\": \"user\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 268,\n        \"min\": 0,\n        \"max\": 942,\n        \"num_unique_values\": 942,\n        \"samples\": [\n          332,\n          598,\n          862\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"item\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 300,\n        \"min\": 0,\n        \"max\": 1673,\n        \"num_unique_values\": 1447,\n        \"samples\": [\n          629,\n          515,\n          373\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 4,\n        \"max\": 5,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          5,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5378865,\n        \"min\": 874724710,\n        \"max\": 893286638,\n        \"num_unique_values\": 32227,\n        \"samples\": [\n          886261387,\n          887853735\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "krQs-C-KbIIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create edge_index tensor (shape: [2, num_edges])\n",
        "edge_index = torch.tensor(ratings[['user', 'item']].values.T, dtype=torch.long)\n",
        "print(\"Edge index shape:\", edge_index.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knjpkgCza07w",
        "outputId": "c5c65b15-1528-418f-9a91-ee11b01acd12"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edge index shape: torch.Size([2, 55375])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_sparse import SparseTensor\n",
        "\n",
        "def build_norm_adj(num_users, num_items, edge_index):\n",
        "    # Shift item indices so that users and items share one index space\n",
        "    edge_index = edge_index.clone()\n",
        "    edge_index[1] += num_users  # items now start at index num_users\n",
        "\n",
        "    # Create reverse edges to form a symmetric graph\n",
        "    row, col = edge_index\n",
        "    rev_edge_index = torch.stack([col, row], dim=0)\n",
        "    full_edge_index = torch.cat([edge_index, rev_edge_index], dim=1)\n",
        "\n",
        "    N = num_users + num_items  # Total nodes\n",
        "    # Create the sparse adjacency matrix (implicitly with value 1 for every edge)\n",
        "    adj = SparseTensor(row=full_edge_index[0], col=full_edge_index[1], sparse_sizes=(N, N))\n",
        "\n",
        "    # Compute degree and its inverse square root\n",
        "    deg = adj.sum(dim=1).to(torch.float)\n",
        "    deg_inv_sqrt = deg.pow(-0.5)\n",
        "    deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
        "\n",
        "    # Get the COO representation of the sparse tensor\n",
        "    row, col, val = adj.coo()\n",
        "    # If no values were set, use 1 for each edge\n",
        "    if val is None:\n",
        "        val = torch.ones_like(row, dtype=torch.float)\n",
        "\n",
        "    # Normalize the values: D^(-1/2) * A * D^(-1/2)\n",
        "    norm_val = deg_inv_sqrt[row] * val * deg_inv_sqrt[col]\n",
        "    norm_adj = SparseTensor(row=row, col=col, value=norm_val, sparse_sizes=(N, N))\n",
        "\n",
        "    return norm_adj\n",
        "\n",
        "norm_adj = build_norm_adj(num_users, num_items, edge_index)\n",
        "print(\"Normalized adjacency matrix built!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyouVdLibI6a",
        "outputId": "88c27977-4029-4daa-a6e4-0e94dc6c4505"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized adjacency matrix built!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LightGCN(nn.Module):\n",
        "    def __init__(self, num_users, num_items, emb_size, num_layers):\n",
        "        super(LightGCN, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.num_users = num_users\n",
        "        self.num_items = num_items\n",
        "\n",
        "        # Initialize embeddings for users and items\n",
        "        self.user_embedding = nn.Embedding(num_users, emb_size)\n",
        "        self.item_embedding = nn.Embedding(num_items, emb_size)\n",
        "        nn.init.xavier_uniform_(self.user_embedding.weight)\n",
        "        nn.init.xavier_uniform_(self.item_embedding.weight)\n",
        "\n",
        "    def forward(self, norm_adj):\n",
        "        # Concatenate user and item embeddings into one tensor.\n",
        "        all_embeddings = torch.cat([self.user_embedding.weight, self.item_embedding.weight], dim=0)\n",
        "        embeddings_list = [all_embeddings]\n",
        "\n",
        "        # Propagate embeddings through the graph for num_layers iterations\n",
        "        for _ in range(self.num_layers):\n",
        "            # Use the matmul method of SparseTensor instead of torch.sparse.mm\n",
        "            all_embeddings = norm_adj.matmul(all_embeddings)\n",
        "            embeddings_list.append(all_embeddings)\n",
        "\n",
        "        # Average the embeddings from all layers (including the initial ones)\n",
        "        final_embedding = sum(embeddings_list) / (self.num_layers + 1)\n",
        "\n",
        "        # Split back into user and item embeddings\n",
        "        user_emb, item_emb = final_embedding.split([self.num_users, self.num_items])\n",
        "        return user_emb, item_emb\n",
        "\n",
        "    def get_score(self, user_emb, item_emb, users, items):\n",
        "        # Dot product between user and item embeddings as a recommendation score\n",
        "        u_emb = user_emb[users]\n",
        "        i_emb = item_emb[items]\n",
        "        return (u_emb * i_emb).sum(dim=1)\n",
        "\n",
        "# Set hyperparameters\n",
        "embedding_size = 64\n",
        "num_layers = 2\n",
        "\n",
        "# Create the model instance\n",
        "model = LightGCN(num_users, num_items, embedding_size, num_layers)\n",
        "print(\"LightGCN model created!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40GPUzNNevGB",
        "outputId": "6f2214bb-78f5-4bae-dcd3-6ebaa840f79d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LightGCN model created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch.optim as optim\n",
        "\n",
        "# Create a dictionary mapping each user to their set of positive items\n",
        "user_item_dict = ratings.groupby('user')['item'].apply(set).to_dict()\n",
        "\n",
        "def sample_negative(user):\n",
        "    # Randomly sample an item that the user has NOT interacted with\n",
        "    while True:\n",
        "        neg_item = random.randint(0, num_items - 1)\n",
        "        if neg_item not in user_item_dict[user]:\n",
        "            return neg_item\n",
        "\n",
        "def bpr_loss(user_emb, item_emb, batch):\n",
        "    users, pos_items, neg_items = [], [], []\n",
        "    for (user, pos_item) in batch:\n",
        "        users.append(user)\n",
        "        pos_items.append(pos_item)\n",
        "        neg_items.append(sample_negative(user))\n",
        "\n",
        "    users = torch.tensor(users, dtype=torch.long)\n",
        "    pos_items = torch.tensor(pos_items, dtype=torch.long)\n",
        "    neg_items = torch.tensor(neg_items, dtype=torch.long)\n",
        "\n",
        "    pos_scores = model.get_score(user_emb, item_emb, users, pos_items)\n",
        "    neg_scores = model.get_score(user_emb, item_emb, users, neg_items)\n",
        "\n",
        "    loss = -torch.log(torch.sigmoid(pos_scores - neg_scores)).mean()\n",
        "    return loss\n",
        "\n",
        "# Prepare the optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "u3rpMk5NfeQh"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of all positive (user, item) pairs\n",
        "pos_pairs = list(ratings[['user', 'item']].itertuples(index=False, name=None))\n",
        "\n",
        "num_epochs = 1000\n",
        "batch_size = 1024  # Adjust the batch size if needed\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass: compute embeddings from the normalized adjacency matrix\n",
        "    user_emb, item_emb = model(norm_adj)\n",
        "\n",
        "    # Randomly sample a batch of positive pairs\n",
        "    batch = random.sample(pos_pairs, min(batch_size, len(pos_pairs)))\n",
        "\n",
        "    loss = bpr_loss(user_emb, item_emb, batch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "        print(f\"Epoch {epoch:03d}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "print(\"Training finished!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YA4iX2jmfhOz",
        "outputId": "ffaa92b6-063f-4e78-cf38-64203c47bc5d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 005, Loss: 0.6518\n",
            "Epoch 010, Loss: 0.6388\n",
            "Epoch 015, Loss: 0.6248\n",
            "Epoch 020, Loss: 0.6044\n",
            "Epoch 025, Loss: 0.5877\n",
            "Epoch 030, Loss: 0.5766\n",
            "Epoch 035, Loss: 0.5583\n",
            "Epoch 040, Loss: 0.5343\n",
            "Epoch 045, Loss: 0.5146\n",
            "Epoch 050, Loss: 0.4886\n",
            "Epoch 055, Loss: 0.4637\n",
            "Epoch 060, Loss: 0.4655\n",
            "Epoch 065, Loss: 0.4487\n",
            "Epoch 070, Loss: 0.4137\n",
            "Epoch 075, Loss: 0.4049\n",
            "Epoch 080, Loss: 0.3928\n",
            "Epoch 085, Loss: 0.3786\n",
            "Epoch 090, Loss: 0.3649\n",
            "Epoch 095, Loss: 0.3584\n",
            "Epoch 100, Loss: 0.3474\n",
            "Epoch 105, Loss: 0.3443\n",
            "Epoch 110, Loss: 0.3468\n",
            "Epoch 115, Loss: 0.3405\n",
            "Epoch 120, Loss: 0.3349\n",
            "Epoch 125, Loss: 0.3291\n",
            "Epoch 130, Loss: 0.3376\n",
            "Epoch 135, Loss: 0.3228\n",
            "Epoch 140, Loss: 0.3338\n",
            "Epoch 145, Loss: 0.3085\n",
            "Epoch 150, Loss: 0.3026\n",
            "Epoch 155, Loss: 0.2782\n",
            "Epoch 160, Loss: 0.3013\n",
            "Epoch 165, Loss: 0.2980\n",
            "Epoch 170, Loss: 0.3091\n",
            "Epoch 175, Loss: 0.3075\n",
            "Epoch 180, Loss: 0.2985\n",
            "Epoch 185, Loss: 0.3057\n",
            "Epoch 190, Loss: 0.3076\n",
            "Epoch 195, Loss: 0.2712\n",
            "Epoch 200, Loss: 0.2959\n",
            "Epoch 205, Loss: 0.2745\n",
            "Epoch 210, Loss: 0.2846\n",
            "Epoch 215, Loss: 0.2862\n",
            "Epoch 220, Loss: 0.3332\n",
            "Epoch 225, Loss: 0.3165\n",
            "Epoch 230, Loss: 0.2953\n",
            "Epoch 235, Loss: 0.2853\n",
            "Epoch 240, Loss: 0.2873\n",
            "Epoch 245, Loss: 0.2804\n",
            "Epoch 250, Loss: 0.2978\n",
            "Epoch 255, Loss: 0.2817\n",
            "Epoch 260, Loss: 0.3015\n",
            "Epoch 265, Loss: 0.2808\n",
            "Epoch 270, Loss: 0.2975\n",
            "Epoch 275, Loss: 0.2728\n",
            "Epoch 280, Loss: 0.2867\n",
            "Epoch 285, Loss: 0.2945\n",
            "Epoch 290, Loss: 0.2643\n",
            "Epoch 295, Loss: 0.3173\n",
            "Epoch 300, Loss: 0.2906\n",
            "Epoch 305, Loss: 0.2730\n",
            "Epoch 310, Loss: 0.2963\n",
            "Epoch 315, Loss: 0.2878\n",
            "Epoch 320, Loss: 0.2709\n",
            "Epoch 325, Loss: 0.2905\n",
            "Epoch 330, Loss: 0.2940\n",
            "Epoch 335, Loss: 0.2706\n",
            "Epoch 340, Loss: 0.3005\n",
            "Epoch 345, Loss: 0.2816\n",
            "Epoch 350, Loss: 0.3002\n",
            "Epoch 355, Loss: 0.3417\n",
            "Epoch 360, Loss: 0.2875\n",
            "Epoch 365, Loss: 0.2931\n",
            "Epoch 370, Loss: 0.2597\n",
            "Epoch 375, Loss: 0.2857\n",
            "Epoch 380, Loss: 0.2686\n",
            "Epoch 385, Loss: 0.2610\n",
            "Epoch 390, Loss: 0.3006\n",
            "Epoch 395, Loss: 0.2461\n",
            "Epoch 400, Loss: 0.2764\n",
            "Epoch 405, Loss: 0.2818\n",
            "Epoch 410, Loss: 0.2410\n",
            "Epoch 415, Loss: 0.2722\n",
            "Epoch 420, Loss: 0.2870\n",
            "Epoch 425, Loss: 0.2589\n",
            "Epoch 430, Loss: 0.2739\n",
            "Epoch 435, Loss: 0.2946\n",
            "Epoch 440, Loss: 0.2620\n",
            "Epoch 445, Loss: 0.2890\n",
            "Epoch 450, Loss: 0.2678\n",
            "Epoch 455, Loss: 0.2553\n",
            "Epoch 460, Loss: 0.2820\n",
            "Epoch 465, Loss: 0.2555\n",
            "Epoch 470, Loss: 0.2779\n",
            "Epoch 475, Loss: 0.2952\n",
            "Epoch 480, Loss: 0.2687\n",
            "Epoch 485, Loss: 0.2960\n",
            "Epoch 490, Loss: 0.2826\n",
            "Epoch 495, Loss: 0.2794\n",
            "Epoch 500, Loss: 0.2416\n",
            "Epoch 505, Loss: 0.2676\n",
            "Epoch 510, Loss: 0.2677\n",
            "Epoch 515, Loss: 0.2998\n",
            "Epoch 520, Loss: 0.2809\n",
            "Epoch 525, Loss: 0.2651\n",
            "Epoch 530, Loss: 0.2870\n",
            "Epoch 535, Loss: 0.2791\n",
            "Epoch 540, Loss: 0.2789\n",
            "Epoch 545, Loss: 0.2789\n",
            "Epoch 550, Loss: 0.2542\n",
            "Epoch 555, Loss: 0.2616\n",
            "Epoch 560, Loss: 0.2825\n",
            "Epoch 565, Loss: 0.2520\n",
            "Epoch 570, Loss: 0.2626\n",
            "Epoch 575, Loss: 0.2891\n",
            "Epoch 580, Loss: 0.2983\n",
            "Epoch 585, Loss: 0.2529\n",
            "Epoch 590, Loss: 0.2622\n",
            "Epoch 595, Loss: 0.2470\n",
            "Epoch 600, Loss: 0.2725\n",
            "Epoch 605, Loss: 0.2547\n",
            "Epoch 610, Loss: 0.2870\n",
            "Epoch 615, Loss: 0.2730\n",
            "Epoch 620, Loss: 0.2676\n",
            "Epoch 625, Loss: 0.2706\n",
            "Epoch 630, Loss: 0.2762\n",
            "Epoch 635, Loss: 0.2597\n",
            "Epoch 640, Loss: 0.2766\n",
            "Epoch 645, Loss: 0.2575\n",
            "Epoch 650, Loss: 0.2575\n",
            "Epoch 655, Loss: 0.2460\n",
            "Epoch 660, Loss: 0.2540\n",
            "Epoch 665, Loss: 0.2411\n",
            "Epoch 670, Loss: 0.2550\n",
            "Epoch 675, Loss: 0.2433\n",
            "Epoch 680, Loss: 0.2510\n",
            "Epoch 685, Loss: 0.2671\n",
            "Epoch 690, Loss: 0.2710\n",
            "Epoch 695, Loss: 0.2690\n",
            "Epoch 700, Loss: 0.2511\n",
            "Epoch 705, Loss: 0.2445\n",
            "Epoch 710, Loss: 0.2388\n",
            "Epoch 715, Loss: 0.2632\n",
            "Epoch 720, Loss: 0.2449\n",
            "Epoch 725, Loss: 0.2425\n",
            "Epoch 730, Loss: 0.2797\n",
            "Epoch 735, Loss: 0.2325\n",
            "Epoch 740, Loss: 0.2525\n",
            "Epoch 745, Loss: 0.2658\n",
            "Epoch 750, Loss: 0.2645\n",
            "Epoch 755, Loss: 0.2497\n",
            "Epoch 760, Loss: 0.2639\n",
            "Epoch 765, Loss: 0.2706\n",
            "Epoch 770, Loss: 0.2519\n",
            "Epoch 775, Loss: 0.2372\n",
            "Epoch 780, Loss: 0.2442\n",
            "Epoch 785, Loss: 0.2642\n",
            "Epoch 790, Loss: 0.2452\n",
            "Epoch 795, Loss: 0.2771\n",
            "Epoch 800, Loss: 0.2280\n",
            "Epoch 805, Loss: 0.2574\n",
            "Epoch 810, Loss: 0.2598\n",
            "Epoch 815, Loss: 0.2661\n",
            "Epoch 820, Loss: 0.2616\n",
            "Epoch 825, Loss: 0.2620\n",
            "Epoch 830, Loss: 0.2368\n",
            "Epoch 835, Loss: 0.2733\n",
            "Epoch 840, Loss: 0.2720\n",
            "Epoch 845, Loss: 0.2514\n",
            "Epoch 850, Loss: 0.2505\n",
            "Epoch 855, Loss: 0.2646\n",
            "Epoch 860, Loss: 0.2531\n",
            "Epoch 865, Loss: 0.2590\n",
            "Epoch 870, Loss: 0.2295\n",
            "Epoch 875, Loss: 0.2521\n",
            "Epoch 880, Loss: 0.2430\n",
            "Epoch 885, Loss: 0.2610\n",
            "Epoch 890, Loss: 0.2495\n",
            "Epoch 895, Loss: 0.2662\n",
            "Epoch 900, Loss: 0.2554\n",
            "Epoch 905, Loss: 0.2422\n",
            "Epoch 910, Loss: 0.2453\n",
            "Epoch 915, Loss: 0.2539\n",
            "Epoch 920, Loss: 0.2505\n",
            "Epoch 925, Loss: 0.2605\n",
            "Epoch 930, Loss: 0.2429\n",
            "Epoch 935, Loss: 0.2454\n",
            "Epoch 940, Loss: 0.2452\n",
            "Epoch 945, Loss: 0.2665\n",
            "Epoch 950, Loss: 0.2438\n",
            "Epoch 955, Loss: 0.2302\n",
            "Epoch 960, Loss: 0.2544\n",
            "Epoch 965, Loss: 0.2188\n",
            "Epoch 970, Loss: 0.2237\n",
            "Epoch 975, Loss: 0.2411\n",
            "Epoch 980, Loss: 0.2337\n",
            "Epoch 985, Loss: 0.2511\n",
            "Epoch 990, Loss: 0.2420\n",
            "Epoch 995, Loss: 0.2544\n",
            "Epoch 1000, Loss: 0.2535\n",
            "Training finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend(model, norm_adj, user_id, top_k=10):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        user_emb, item_emb = model(norm_adj)\n",
        "        # Compute scores for all items for this user\n",
        "        scores = (user_emb[user_id].unsqueeze(0) * item_emb).sum(dim=1)\n",
        "        _, top_items = torch.topk(scores, top_k)\n",
        "    return top_items\n",
        "\n",
        "# Example: Get top-10 recommendations for user 0\n",
        "user_id = 0\n",
        "recommended_items = recommend(model, norm_adj, user_id, top_k=10)\n",
        "print(f\"Top 10 recommendations for user {user_id}:\", recommended_items.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbWHhktVge2m",
        "outputId": "3fe8e843-44ad-484a-928d-c7abc4197d90"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 recommendations for user 0: [49, 99, 97, 173, 180, 126, 171, 0, 55, 63]\n"
          ]
        }
      ]
    }
  ]
}